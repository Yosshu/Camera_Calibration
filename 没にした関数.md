# 没にした関数

    def Image1to2(self, x, y):      # 1カメ画像の点から2カメ画像のエピポーラ線を求める関数
        undist_i1 = cv2.undistortPoints(np.float32([x,y]), self.mtx, self.dist, None, self.mtx)
        obj_i1x = undist_i1[0][0][0]                                            # 対象物の1カメ画像座標　クリックした点
        obj_i1y = undist_i1[0][0][1]
        #obj_i1x = x                                            # 対象物の1カメ画像座標　クリックした点
        #obj_i1y = y
        obj_n1x = (obj_i1x - self.mtx[0][2]) / self.mtx[0][0]                   # 対象物の1カメ正規化座標　原点を真ん中にしてから，焦点距離で割る
        obj_n1y = (obj_i1y - self.mtx[1][2]) / self.mtx[1][1]
        obj_n1 = [[obj_n1x], [obj_n1y], [1]]                                    # 対象物の1カメ正規化画像座標系を1カメカメラ座標系に変換
        #self.obj_w = (np.linalg.inv(R)) @ (np.array(obj_n1) - np.array(tvecs))
        self.obj_w = (self.R.T) @ (np.array(obj_n1) - np.array(self.tvecs))                    # obj_n1を世界座標系に変換              Ｗ = Ｒ1^T (Ｃ1 - ｔ1)
        obj_c2 = np.array(self.R2) @ np.array(self.obj_w) + np.array(self.tvecs2)              # obj_wを2カメのカメラ座標系に変換     Ｃ2 = Ｒ2Ｗ + ｔ2
        self.obj_i2 = self.mtx2 @ (obj_c2/obj_c2[0][2])                                   # obj_c2を2カメの画像座標に変換
        
        #self.camera1_w = (np.linalg.inv(R)) @ (np.array([[0], [0], [0]]) - np.array(tvecs))     # 1カメのワールド座標        Ｗ = Ｒ1^T (Ｃ1 - ｔ1)
        self.camera1_w = (self.R.T) @ (np.array([[0], [0], [0]]) - np.array(self.tvecs))       # 1カメのワールド座標        Ｗ = Ｒ1^T (Ｃ1 - ｔ1)
        camera1_c2 = np.array(self.R2) @ self.camera1_w + np.array(self.tvecs2)                 # 2カメのカメラ座標系での1カメの位置
        camera1_i2 = self.mtx2 @ (camera1_c2/camera1_c2[0][2])                       # 2カメの画像座標系での1カメの位置

        self.img_line = self.img_axes2.copy()       # img_axes2に上書きしたくないから，複製したものを用意
        slope_i2 = (camera1_i2[0][1] - self.obj_i2[0][1])/(camera1_i2[0][0] - self.obj_i2[0][0])  # 線の傾き

        self.startpoint_i2y  = slope_i2*(0                    - self.obj_i2[0][0]) + self.obj_i2[0][1]           # エピポーラ線の2カメ画像の左端のy座標を求める
        self.endpoint_i2y   = slope_i2*(self.img_axes2.shape[1]   - self.obj_i2[0][0]) + self.obj_i2[0][1]      # エピポーラ線の2カメ画像の右端のy座標を求める
        self.img_line = cv2.line(self.img_line, (0, int(self.startpoint_i2y)), (self.img_axes2.shape[1], int(self.endpoint_i2y)), (0,255,255), 5)    # エピポーラ線を引く
        return slope_i2     # この関数内で求まった傾きを返す（self.slope_i2はonMouse()内で更新されるため，self.slope_i2はクリックした時限定の傾き）

    def Image2to1(self, x, y, slope_i2):    # 2カメ画像のエピポーラ線上の1点を指定することでその場所のワールド座標を求める関数（まだ1マスが1にはなってない）
        img_line2 = self.img_line.copy()
        option_y = slope_i2*(x - self.obj_i2[0][0][0]) + self.obj_i2[0][1][0]    # クリックされたx座標から線のy座標を求める
        option_y = option_y[0]  # 何故か配列になっているため[]をはずす
        if slope_i2 != 0:  # 線の傾きが0でないなら，
            option_x = (y - self.obj_i2[0][1][0])/slope_i2 + self.obj_i2[0][0][0]    # クリックされたy座標から線のx座標を求める
            option_x = option_x[0]  # 同じく何故か配列になっているため[]をはずす
            diff1 = abs(option_y - y)   # それぞれの差を求める
            diff2 = abs(option_x - x)
            if diff1 <= diff2:  # 差が小さい方を画像座標として採用する
                self.obj2_i2x = x
                self.obj2_i2y = option_y
            else:
                self.obj2_i2x = option_x
                self.obj2_i2y = y
        else:   # 線の傾きが0なら，y座標が求められないから，xとoption_yを画像座標として採用
            self.obj2_i2x = x
            self.obj2_i2y = option_y

        cv2.circle(img_line2, (int(self.obj2_i2x),int(self.obj2_i2y)), 8, (0, 165, 255), thickness=-1)    # 線上のどの点を選択したのかを描画
        undist_i2 = cv2.undistortPoints(np.float32([self.obj2_i2x,self.obj2_i2y]), self.mtx2, self.dist2, None, self.mtx2)
        obj2_i2x_undist = undist_i2[0][0][0]
        obj2_i2y_undist = undist_i2[0][0][1]
        obj2_n2x = (obj2_i2x_undist - self.mtx2[0][2]) / self.mtx2[0][0]       # 対象物の2カメ正規化座標　原点を真ん中にしてから，焦点距離で割る   
        obj2_n2y = (obj2_i2y_undist - self.mtx2[1][2]) / self.mtx2[1][1]
        obj2_n2 = [[obj2_n2x], [obj2_n2y], [1]]
        obj2_w = (np.array(self.R2.T)) @ (np.array(obj2_n2) - np.array(self.tvecs2))    # obj_n2を世界座標系に変換              Ｗ = Ｒ2^T (Ｃ2 - ｔ)

        camera2_w = (self.R2.T) @ (np.array([[0], [0], [0]]) - np.array(self.tvecs2))       # 2カメのワールド座標        Ｗ = Ｒ2^T (Ｃ2 - ｔ)

        line1 = np.hstack((self.camera1_w[0].T, self.obj_w[0].T)).reshape(2, 3)
        line2 = np.hstack((camera2_w[0].T, obj2_w[0].T)).reshape(2, 3)
        res = self.distance_2lines(line1,line2)
        return res, img_line2



## esti_ros.py
def angleDiff(self,img):        # ロボットの向きと目標方向の角度差，ロボットと目標位置の距離，左クリックしたのか右クリックしたのかを返す関数
        ret1,reds_i= findSquare(img,57,67,255)       # 赤パネルの画像座標
        ret2,greens_i = findSquare(img,98,142,53)    # 緑パネルの画像座標
        ret3 = ret1 and ret2
        red_i,green_i = nearest(ret3,reds_i,greens_i)

        if (self.LRMclick == 'L' or self.LRMclick == 'R') and ret1 and ret2:     # 左クリックか右クリックしていたら
            red_w = self.pointFixZ(red_i[0],red_i[1],0.5)       # 赤パネルのワールド座標
            red_w_xy = np.array([red_w[0],red_w[1]])            # 赤パネルのワールド座標のXw,Yw
            green_w = self.pointFixZ(green_i[0],green_i[1],0.5) # 緑パネルのワールド座標
            green_w_xy = np.array([green_w[0],green_w[1]])      # 緑パネルのワールド座標のXw,Yw
            robot_vector = np.array(red_w_xy - green_w_xy)      # ロボットの向きベクトル
            target_w_xy = np.array([self.target_w[0],self.target_w[1]]) # 目標位置のワールド座標のXw,Yw
            robot_wx = (red_w[0]+green_w[0])/2                  # ロボットのワールド座標のXw
            robot_wy = (red_w[1]+green_w[1])/2                  # ロボットのワールド座標のYw
            robot_w_xy = np.array([robot_wx,robot_wy])          # ロボットのワールド座標のXw,Yw
            target_vector = np.array(target_w_xy - robot_w_xy)  # 目的方向のベクトル

            angle = tangent_angle(robot_vector,target_vector)   # ロボットの向きと目標方向の角度差
            
            distance = math.sqrt((target_w_xy[0]-robot_w_xy[0])**2 + (target_w_xy[1]-robot_w_xy[1])**2)     # ロボットと目標位置の距離


            robot_ix = (red_i[0]+green_i[0])/2
            robot_iy = (red_i[1]+green_i[1])/2
            
            cv2.arrowedLine(img,                                # 矢印
                pt1=(int(robot_ix), int(robot_iy)),
                pt2=(int(self.target_i[0]), int(self.target_i[1])),
                color=(0, 255, 255),
                thickness=3,
                line_type=cv2.LINE_4,
                shift=0,
                tipLength=0.1)
            
            cv2.imshow("camera1",img)
            
            return True,angle,distance,self.LRMclick
        return False,None,None,None
